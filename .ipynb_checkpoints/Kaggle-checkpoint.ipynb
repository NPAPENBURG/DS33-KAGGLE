{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "871e770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libaries that I will be using\n",
    "\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score # k-fold CV\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV # Hyperparameter tuning\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ccc2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data wrangle fuction\n",
    "def wrangle(fm_path, tv_path=None):\n",
    "    if tv_path:\n",
    "        df = pd.merge(pd.read_csv(fm_path, \n",
    "                              # Turn these values into NaN    \n",
    "                              na_values=[0, -2.000000e-08],\n",
    "                              # Turn this column into datetime\n",
    "                              parse_dates=['date_recorded']),\n",
    "                  # Turn the 'id' column into the dataframe index\n",
    "                  pd.read_csv(tv_path)).set_index('id')\n",
    "    else:\n",
    "        df = pd.read_csv(fm_path, \n",
    "                     na_values=[0, -2.000000e-08],\n",
    "                     parse_dates=['date_recorded'],\n",
    "                     index_col='id')\n",
    "\n",
    "    # Drop constant columns\n",
    "    df.drop(columns=['recorded_by'], inplace=True)\n",
    "\n",
    "    # Create age feature\n",
    "    df['pump_age'] = df['date_recorded'].dt.year - df['construction_year']\n",
    "    df.drop(columns='date_recorded', inplace=True)\n",
    "\n",
    "    # Drop HCCCs\n",
    "    cutoff = 100\n",
    "    drop_cols = [col for col in df.select_dtypes('object').columns\n",
    "              if df[col].nunique() > cutoff]\n",
    "    df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "    # Drop duplicate columns\n",
    "    dupe_cols = [col for col in df.head(100).T.duplicated().index\n",
    "               if df.head(100).T.duplicated()[col]]\n",
    "    df.drop(columns=dupe_cols, inplace=True)      \n",
    "    \n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6257d271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the datasets and using the wrangle function on them\n",
    "df = wrangle(fm_path='train_features.csv',\n",
    "             tv_path='train_labels.csv')\n",
    "\n",
    "X_test = wrangle(fm_path='test_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb3e1b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into my X matrix and y vector\n",
    "# We want to predict what water pumps need to be repaired\n",
    "target = 'status_group'\n",
    "y = df[target]\n",
    "X = df.drop(columns = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d373987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y, test_size=.2, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d89312a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.5429828068772491\n"
     ]
    }
   ],
   "source": [
    "# Establishing a baseline\n",
    "#Checking to see what the current y counts look like.\n",
    "y.value_counts()\n",
    "\n",
    "# Turning the y counts into floats(percents)\n",
    "y.value_counts(normalize=True)\n",
    "\n",
    "# The baseline will always be the majority in categorical\n",
    "baseline = y.value_counts(normalize=True).max()\n",
    "\n",
    "print('Baseline:', baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2884c5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bigpa\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('onehotencoder',\n",
       "                 OneHotEncoder(cols=['basin', 'region', 'public_meeting',\n",
       "                                     'scheme_management', 'permit',\n",
       "                                     'extraction_type', 'extraction_type_group',\n",
       "                                     'extraction_type_class', 'management',\n",
       "                                     'management_group', 'payment',\n",
       "                                     'payment_type', 'water_quality',\n",
       "                                     'quality_group', 'quantity', 'source',\n",
       "                                     'source_type', 'source_class',\n",
       "                                     'waterpoint_type',\n",
       "                                     'waterpoint_type_group'],\n",
       "                               use_cat_names=True)),\n",
       "                ('simpleimputer', SimpleImputer()),\n",
       "                ('standardscaler', StandardScaler()),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### FIRST MODEL: Logistic Regression\n",
    "### TUNING IS FURTHER DOWN\n",
    "\n",
    "model_lr = make_pipeline(\n",
    "            OneHotEncoder(use_cat_names=True),\n",
    "            SimpleImputer(strategy='mean'),\n",
    "            StandardScaler(),\n",
    "            LogisticRegression()\n",
    "            )\n",
    "model_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31873e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ordinalencoder',\n",
       "                 OrdinalEncoder(cols=['basin', 'region', 'public_meeting',\n",
       "                                      'scheme_management', 'permit',\n",
       "                                      'extraction_type',\n",
       "                                      'extraction_type_group',\n",
       "                                      'extraction_type_class', 'management',\n",
       "                                      'management_group', 'payment',\n",
       "                                      'payment_type', 'water_quality',\n",
       "                                      'quality_group', 'quantity', 'source',\n",
       "                                      'source_type', 'source_class',\n",
       "                                      'waterpoint_type',\n",
       "                                      'waterpoin...\n",
       "communal standpipe             2\n",
       "communal standpipe multiple    3\n",
       "improved spring                4\n",
       "other                          5\n",
       "cattle trough                  6\n",
       "dam                            7\n",
       "NaN                           -2\n",
       "dtype: int64},\n",
       "                                         {'col': 'waterpoint_type_group',\n",
       "                                          'data_type': dtype('O'),\n",
       "                                          'mapping': hand pump             1\n",
       "communal standpipe    2\n",
       "improved spring       3\n",
       "other                 4\n",
       "cattle trough         5\n",
       "dam                   6\n",
       "NaN                  -2\n",
       "dtype: int64}])),\n",
       "                ('simpleimputer', SimpleImputer()),\n",
       "                ('decisiontreeclassifier',\n",
       "                 DecisionTreeClassifier(max_depth=16, random_state=42))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SECOND MODEL: Decision tree classifier\n",
    "### TUNING IS FURTHER DOWN\n",
    "\n",
    "model_dt = make_pipeline(\n",
    "            OrdinalEncoder(),\n",
    "            SimpleImputer(strategy='mean'),\n",
    "            DecisionTreeClassifier(random_state=42, max_depth=16)\n",
    "            )\n",
    "model_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a468be7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest training accuracy: 0.9488885966066026\n",
      "Random Forest validation accuracy: 0.8002946127946128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### THIRD MODEL: RandomForest\n",
    "### TUNING IS FURTHER DOWN\n",
    "\n",
    "model_rf = make_pipeline(\n",
    "            OrdinalEncoder(),\n",
    "            SimpleImputer(strategy='mean'),\n",
    "            RandomForestClassifier(random_state=42,n_estimators=100,n_jobs=-1, max_depth=20)\n",
    "            )\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Random Forest training accuracy:', model_rf.score(X_train, y_train))\n",
    "print('Random Forest validation accuracy:', model_rf.score(X_val, y_val))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4095606c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-7056d7f6450b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mmodel_rfgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### TUNING RANDOMFOREST\n",
    "clf = make_pipeline(\n",
    "    OrdinalEncoder(),\n",
    "    SimpleImputer(),\n",
    "    RandomForestClassifier(n_estimators=25, random_state=42)\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'simpleimputer__strategy': ['mean', 'median'],\n",
    "    'randomforestclassifier__max_depth': range(5,40,5),\n",
    "    'randomforestclassifier__n_estimators': range(25, 125, 25)\n",
    "}\n",
    "\n",
    "model_rfgs = GridSearchCV(\n",
    "    clf,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_rfgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdab256b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the best parameters\n",
    "model_rfgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd9609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the best score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb7c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rfgs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8214cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check Metrics\n",
    "\n",
    "#Logistic Regresion Metrics\n",
    "\n",
    "print('Logistic Regresion training accuracy:', model_lr.score(X_train, y_train))\n",
    "print('Logistic Regresion validation accuracy:', model_lr.score(X_val, y_val))\n",
    "print()\n",
    "#Logistic Decision Tree\n",
    "\n",
    "print('Decision Tree training accuracy:', model_dt.score(X_train, y_train))\n",
    "print('Decision Tree validation accuracy:', model_dt.score(X_val, y_val))\n",
    "print()\n",
    "\n",
    "#LogisticRandom Forest\n",
    "\n",
    "print('Random Forest training accuracy:', model_rf.score(X_train, y_train))\n",
    "print('Random Forest validation accuracy:', model_rf.score(X_val, y_val))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828e2c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECICION TREE HYPERPARAMETER TUNING\n",
    "depths = range(2,38,2)\n",
    "\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "for depth in depths:\n",
    "  tree_model = make_pipeline(\n",
    "      OrdinalEncoder(),\n",
    "      SimpleImputer(strategy='mean'),\n",
    "      DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "  )\n",
    "\n",
    "  tree_model.fit(X_train, y_train)\n",
    "\n",
    "  train_acc.append(tree_model.score(X_train, y_train))\n",
    "  val_acc.append(tree_model.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a plot for the decision tree\n",
    "plt.plot(depths, train_acc, color='blue', label='training')\n",
    "plt.plot(depths, val_acc, color='orange', label='validation')\n",
    "\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b9233b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM HYPERPARAMETER TUNING\n",
    "depths = range(2,38,2)\n",
    "\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "\n",
    "for depth in depths:\n",
    "  tree_model = make_pipeline(\n",
    "      OrdinalEncoder(),\n",
    "      SimpleImputer(strategy='mean'),\n",
    "      RandomForestClassifier(max_depth=depth, random_state=42,n_estimators=100, n_jobs=-1)\n",
    "  )\n",
    "\n",
    "  tree_model.fit(X_train, y_train)\n",
    "\n",
    "  train_acc.append(tree_model.score(X_train, y_train))\n",
    "  val_acc.append(tree_model.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87306f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a plot for the random forest\n",
    "plt.plot(depths, train_acc, color='blue', label='training')\n",
    "plt.plot(depths, val_acc, color='orange', label='validation')\n",
    "\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fa9a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Explain the decisiontree\n",
    "\n",
    "coefficients = model_dt.named_steps['decisiontreeclassifier']\n",
    "features = model_dt.named_steps['ordinalencoder'].get_feature_names()\n",
    "importances = model_dt.named_steps['decisiontreeclassifier'].feature_importances_\n",
    "\n",
    "feat_imp = pd.Series(importances, index=features).sort_values()\n",
    "feat_imp.tail(10).plot(kind='barh')\n",
    "plt.title('Decision Tree Coefficients');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c12c3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Explain the decisiontree\n",
    "\n",
    "bestimator = model_rfrs.best_estimator_\n",
    "importances = bestimator.named_steps['randomforestclassifier'].feature_importances_\n",
    "features = X_train.columns\n",
    "feat_imp = pd.Series(importances, index=features).sort_values()\n",
    "feat_imp.tail(10).plot(kind='barh')\n",
    "plt.xlabel('Reduction in Gini Impurity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d40f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c45f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARE FOR KAGGLE SUBMISSION\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['id'] = X_test.index\n",
    "submission['status_group'] = model_rf.predict(X_test)\n",
    "\n",
    "submission.to_csv('submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6213179",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_rfgs.predict(X_test)\n",
    "submission = pd.DataFrame({'status_group':y_pred}, index=X_test.index)\n",
    "datestamp = pd.Timestamp.now().strftime('%Y-%m-%d_%H%M_')\n",
    "submission.to_csv(f'{datestamp}submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4eaec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
